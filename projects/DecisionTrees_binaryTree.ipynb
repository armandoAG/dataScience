{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "DecisionTrees_base.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPtI_F12pWOA"
      },
      "source": [
        "import torch\n",
        "import pandas\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6SUEXb7pWOD",
        "outputId": "0b274ef7-e46d-46c9-f941-9603416f90fd"
      },
      "source": [
        "#dataset taken from https://www.kaggle.com/yashsawarn/wifi-stretgth-for-rooms\n",
        "\n",
        "def read_dataset(csv_name = 'wifi_localization.txt'):\n",
        "    \"\"\"\n",
        "    Reads a csv dataset \n",
        "    returns it as a pytorch tensor\n",
        "    \"\"\"\n",
        "\n",
        "    data_frame = pandas.read_table(csv_name, delim_whitespace=True, names=('A', 'B', 'C', 'D','E', 'F', 'G', 'ROOM'),\n",
        "                       dtype={'A': np.int64, 'B': np.float64, 'C': np.float64, 'D': np.float64,'E': np.float64,'F': np.float64,'G': np.float64,'ROOM': np.float64})\n",
        "\n",
        "    targets_torch = torch.tensor(data_frame['ROOM'].values)\n",
        "    dataset_torch = torch.tensor(data_frame.values)\n",
        "    print(dataset_torch)\n",
        "    return dataset_torch\n",
        "dataset_torch = read_dataset()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-64., -56., -61.,  ..., -82., -81.,   1.],\n",
            "        [-68., -57., -61.,  ..., -85., -85.,   1.],\n",
            "        [-63., -60., -60.,  ..., -85., -84.,   1.],\n",
            "        ...,\n",
            "        [-62., -59., -46.,  ..., -87., -88.,   4.],\n",
            "        [-62., -58., -52.,  ..., -90., -85.,   4.],\n",
            "        [-59., -50., -45.,  ..., -88., -87.,   4.]], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_XmmnicLS0T"
      },
      "source": [
        "c=torch.randperm(2000)\n",
        "t=dataset_torch[c]\n",
        "partitions = t.split(200)\n",
        "\n",
        "train_data_1, test_data_1 = partitions[0][:140], partitions[0][140:]\n",
        "train_data_2, test_data_2 = partitions[1][:140], partitions[1][140:]\n",
        "train_data_3, test_data_3 = partitions[2][:140], partitions[2][140:]\n",
        "train_data_4, test_data_4 = partitions[3][:140], partitions[3][140:]\n",
        "train_data_5, test_data_5 = partitions[4][:140], partitions[4][140:]\n",
        "train_data_6, test_data_6 = partitions[5][:140], partitions[5][140:]\n",
        "train_data_7, test_data_7 = partitions[6][:140], partitions[6][140:]\n",
        "train_data_8, test_data_8 = partitions[7][:140], partitions[7][140:]\n",
        "train_data_9, test_data_9 = partitions[8][:140], partitions[8][140:]\n",
        "train_data_10, test_data_10 = partitions[9][:140], partitions[9][140:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGvm8DbapWOI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "046ecde5-4573-468e-e5ae-f87e916de91a"
      },
      "source": [
        "%%time\n",
        "\n",
        "class Node_CART:    \n",
        "    def __init__(self, num_classes = 4, ref_CART = None, current_depth = 0):\n",
        "        \"\"\"\n",
        "        Create the node attributes\n",
        "        param num_classes: K number of classes to classify\n",
        "        param ref_cart: reference to the tree containing the node\n",
        "        param current_depth: current depth of the node in the tree\n",
        "        \"\"\"\n",
        "        self.ref_CART = ref_CART\n",
        "        self.threshold_value = 0\n",
        "        self.feature_num = 0\n",
        "        self.node_right = None\n",
        "        self.node_left = None\n",
        "        self.data_torch_partition = None\n",
        "        self.gini = 0\n",
        "        self.dominant_class = None\n",
        "        self.accuracy_dominant_class = None        \n",
        "        self.num_classes = num_classes\n",
        "        self.current_depth = current_depth\n",
        "    \n",
        "    def to_xml(self, current_str = \"\"):\n",
        "        \"\"\"\n",
        "        Recursive function to write the node content to an xml formatted string\n",
        "        param current_str : the xml content so far in the whole tree\n",
        "        return the string with the node content\n",
        "        \"\"\"\n",
        "        str_node = \"<node><thresh>\" + str(self.threshold_value) + \"</thresh>\" + \"<feature>\" + str(self.feature_num) + \"</feature><depth>\" + str(self.current_depth)+ \"</depth>\" \n",
        "        str_node += \"<gini>\" + str(self.gini) + \"</gini>\"\n",
        "        if(self.node_right != None):\n",
        "            str_left = self.node_right.to_xml(current_str)\n",
        "            str_node += str_left\n",
        "        if(self.node_left != None):\n",
        "            str_right = self.node_left.to_xml(current_str)\n",
        "            str_node += str_right\n",
        "            \n",
        "        if(self.is_leaf()):\n",
        "            str_node += \"<dominant_class>\" + str(self.dominant_class) + \"</dominant_class><acc_dominant_class>\"  + str(self.accuracy_dominant_class) + \"</acc_dominant_class>\"\n",
        "        str_node += \"</node>\"\n",
        "        return str_node\n",
        "    \n",
        "    def is_leaf(self):\n",
        "        \"\"\"\n",
        "        Checks whether the node is a leaf\n",
        "        \"\"\"\n",
        "        return (self.node_left == None and self.node_right == None)\n",
        "    \n",
        "    def create_with_children(self, data_torch, current_depth, list_selected_features = [], min_gini = 0.000001):\n",
        "        \"\"\"\n",
        "        Creates a node by selecting the best feature and threshold, and if needed, creating its children\n",
        "        param data_torch: dataset with the current partition to deal with in the node\n",
        "        param current_depth: depth counter for the node\n",
        "        param list_selected_features: list of selected features so far for the CART building process\n",
        "        param min_gini: hyperparmeter selected by the user defining the minimum tolerated gini coefficient for a  node\n",
        "        return the list of selected features so far\n",
        "        \"\"\"        \n",
        "        #update depth of children\n",
        "        depth_children = current_depth + 1\n",
        "        if(depth_children <= self.ref_CART.get_max_depth()):\n",
        "            num_observations = data_torch.shape[0]            \n",
        "            #careful with max depth\n",
        "            #if no threshold and feature were selected, select it using a greedy approach            \n",
        "            (threshold_value, feature_num, gini) = self.select_best_feature_and_thresh(data_torch, list_features_selected = list_selected_features)\n",
        "            list_selected_features += [feature_num]\n",
        "            #store important data in attributes\n",
        "            self.threshold_value = threshold_value\n",
        "            self.feature_num = feature_num\n",
        "            self.data_torch_partition = data_torch\n",
        "            self.gini = gini     \n",
        "                   \n",
        "            num_features = data_torch.shape[1]\n",
        "            #data_torch_left = torch.zeros(1, num_features)\n",
        "            #data_torch_right = torch.zeros(1, num_features)\n",
        "            #create the right and left node data if the current gini is still high            \n",
        "            if(self.gini > min_gini):                \n",
        "                data_torch_left = data_torch[data_torch[:, feature_num] < threshold_value]\n",
        "                data_torch_right = data_torch[data_torch[:, feature_num] >= threshold_value]\n",
        "                #if the new partitions have more than min_observations, make them\n",
        "                if(data_torch_left.shape[0] >= self.ref_CART.get_min_observations() and data_torch_right.shape[0] >= self.ref_CART.get_min_observations()):\n",
        "                    #add data to the right and left children\n",
        "                    self.node_right = Node_CART(num_classes = self.num_classes, ref_CART = self.ref_CART, current_depth = depth_children)\n",
        "                    self.node_left = Node_CART(num_classes = self.num_classes, ref_CART = self.ref_CART, current_depth = depth_children)\n",
        "                    list_selected_features = self.node_right.create_with_children(data_torch_right, depth_children, list_selected_features = list_selected_features)            \n",
        "                    self.node_left.create_with_children( data_torch_left, depth_children, list_selected_features = list_selected_features)\n",
        "        #if is leaf, fill the         \n",
        "        if(self.is_leaf()):            \n",
        "            labels_data = data_torch[:,  -1]\n",
        "            self.dominant_class = torch.mode(labels_data).values.item()\n",
        "            num_obs_label = labels_data[labels_data == self.dominant_class].shape[0]\n",
        "            self.accuracy_dominant_class = num_obs_label / labels_data.shape[0]           \n",
        "            \n",
        "        return list_selected_features\n",
        "    \n",
        "    \n",
        "    def select_best_feature_and_thresh(self, data_torch, list_features_selected = [], num_classes = 4):\n",
        "        \"\"\"\n",
        "        Selects the best feature and threshold that minimizes the gini coefficient\n",
        "        param data_torch: dataset partition to analyze\n",
        "        param list_features_selected list of features selected so far, thus must be ignored \n",
        "        param num_classes: number of K classes to discriminate from \n",
        "        return min_thresh, min_feature, min_gini found for the dataset partition when \n",
        "        selecting the found feature and threshold\n",
        "        \"\"\"       \n",
        "        \n",
        "        #TODO\n",
        "        \n",
        "        feature_list = [0,1,2,3,4,5,6]\n",
        "\n",
        "        new_feature_list = [i for i in feature_list if i not in list_features_selected]\n",
        "\n",
        "\n",
        "        min_gini=1000\n",
        "\n",
        "        for feature in new_feature_list:\n",
        "          threshold_list = data_torch[:, feature].unique()\n",
        "          for thresh in threshold_list:\n",
        "            data_torch_left = data_torch[data_torch[:, feature] < thresh]\n",
        "            data_torch_right = data_torch[data_torch[:, feature] >= thresh]\n",
        "\n",
        "            #gini_pond = (data_torch_left.shape[0]/data_torch.shape[0])*self.calculate_gini(data_torch_left) + (data_torch_right.shape[0]/data_torch.shape[0])*self.calculate_gini(data_torch_right) \n",
        "            entropy_pond = (data_torch_left.shape[0]/data_torch.shape[0])*self.calculate_entropy(data_torch_left) + (data_torch_right.shape[0]/data_torch.shape[0])*self.calculate_entropy(data_torch_right) \n",
        "\n",
        "            if (entropy_pond < min_gini):\n",
        "              #print(\"dentro\", gini_pond)\n",
        "              min_feature = feature\n",
        "              min_thresh = thresh\n",
        "              min_gini = entropy_pond\n",
        "\n",
        "\n",
        "        #return selected cut       \n",
        "        return (min_thresh, min_feature, min_gini)   \n",
        "        \n",
        "    \n",
        "    def calculate_gini(self, data_partition_torch, num_classes = 4):\n",
        "        \"\"\"\n",
        "        Calculates the gini coefficient for a given partition with the given number of classes\n",
        "        param data_partition_torch: current dataset partition as a tensor\n",
        "        param num_classes: K number of classes to discriminate from\n",
        "        returns the calculated gini coefficient\n",
        "        \"\"\"\n",
        "        #TODO\n",
        "        a_k = data_partition_torch[:, -1].unique(return_counts=True)[1]/data_partition_torch.shape[0]\n",
        "\n",
        "        gini = 1 - torch.sum((a_k)**2)\n",
        "        \n",
        "        return gini\n",
        "    \n",
        "    def calculate_entropy(self, data_partition_torch, num_classes = 4):\n",
        "        \"\"\"\n",
        "        Calculates the entropy for a given partition with the given number of classes\n",
        "        param data_partition_torch: current dataset partition as a tensor\n",
        "        param num_classes: K number of classes to discriminate from\n",
        "        returns the calculated entropy\n",
        "        \"\"\"\n",
        "        #TODO\n",
        "        p_k = data_partition_torch[:, -1].unique(return_counts=True)[1]/data_partition_torch.shape[0]\n",
        "\n",
        "        entropy = -torch.sum(p_k*np.log2(p_k))\n",
        "\n",
        "\n",
        "        return entropy\n",
        "    \n",
        "    def evaluate_node(self, input_torch): \n",
        "        \"\"\"\n",
        "        Evaluates an input observation within the node. \n",
        "        If is not a leaf node, send it to the corresponding node\n",
        "        return predicted label\n",
        "        \"\"\"\n",
        "        feature_val_input = input_torch[self.feature_num]\n",
        "        if(self.is_leaf()):\n",
        "            return self.dominant_class\n",
        "        else:\n",
        "            if(feature_val_input < self.threshold_value):\n",
        "                return self.node_left.evaluate_node(input_torch)\n",
        "            else:\n",
        "                return self.node_right.evaluate_node(input_torch)\n",
        "        \n",
        "\n",
        "class CART:\n",
        "    def __init__(self, dataset_torch, max_CART_depth, min_observations = 2):\n",
        "        \"\"\"\n",
        "        CART has only one root node\n",
        "        \"\"\"\n",
        "        #min observations per node\n",
        "        self.min_observations = min_observations\n",
        "        self.root = Node_CART(num_classes = 4, ref_CART = self, current_depth = 0)\n",
        "        self.max_CART_depth = max_CART_depth\n",
        "        self.list_selected_features = []\n",
        "        \n",
        "    def get_root(self):\n",
        "        \"\"\"\n",
        "        Gets tree root\n",
        "        \"\"\"\n",
        "        return self.root\n",
        "    \n",
        "    def get_min_observations(self):\n",
        "        \"\"\"\n",
        "        return min observations per node\n",
        "        \"\"\"\n",
        "        return self.min_observations\n",
        "    \n",
        "    def get_max_depth(self):\n",
        "        \"\"\"\n",
        "        Gets the selected max depth of the tree\n",
        "        \"\"\"\n",
        "        return self.max_CART_depth\n",
        "    \n",
        "    def build_CART(self, data_torch):\n",
        "        \"\"\"\n",
        "        Build CART from root\n",
        "        \"\"\"\n",
        "        self.list_selected_features = self.root.create_with_children(data_torch, current_depth = 0)\n",
        "    \n",
        "    def to_xml(self, xml_file_name):\n",
        "        \"\"\"\n",
        "        write Xml file with tree content\n",
        "        \"\"\"\n",
        "        str_nodes = self.root.to_xml()\n",
        "        file = open(xml_file_name,\"w+\") \n",
        "        file.write(str_nodes)\n",
        "        file.close()\n",
        "        return str_nodes\n",
        "    \n",
        "    \n",
        "    def evaluate_input(self, input_torch):\n",
        "        \"\"\"\n",
        "        Evaluate a specific input in the tree and get the predicted class\n",
        "        \"\"\"\n",
        "        return self.root.evaluate_node(input_torch)\n",
        "        \n",
        "    \n",
        "def train_CART(dataset_torch, name_xml = \"\", max_CART_depth = 3, min_obs_per_leaf = 2): \n",
        "    \"\"\"\n",
        "    Train CART model\n",
        "    \"\"\"\n",
        "    tree = CART(dataset_torch = dataset_torch, max_CART_depth = max_CART_depth, min_observations =  min_obs_per_leaf)\n",
        "    tree.build_CART(dataset_torch)\n",
        "    if(not name_xml == \"\"):\n",
        "        tree.to_xml(name_xml)\n",
        "    return tree\n",
        "\n",
        "def test_CART(tree, testset_torch):\n",
        "    \"\"\"\n",
        "    Test a previously built CART\n",
        "    \"\"\"\n",
        "    #TODO, use tree.evaluate_input(current_observation) for this\n",
        "    \n",
        "    #tree.evaluate_input(testset_torch[750])\n",
        "    c = 0\n",
        "    for i in range(0,testset_torch.shape[0]-1):\n",
        "      if tree.evaluate_input(testset_torch[i]) == testset_torch[i][-1]:\n",
        "        c += 1\n",
        "\n",
        "    accuracy = c / testset_torch.shape[0]\n",
        "    return accuracy\n",
        "\n",
        "        \n",
        "tree = train_CART(dataset_torch, name_xml = \"CART_example.xml\")\n",
        "acc = test_CART(tree, dataset_torch)\n",
        "#acc2 = test_CART(tree, dataset_torch)\n",
        "print(\"Train accuracy:\", acc)\n",
        "#print(\"Test accuracy:\", acc2)\n",
        "    \n",
        "\n",
        "        "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train accuracy: 0.9375\n",
            "CPU times: user 346 ms, sys: 844 µs, total: 347 ms\n",
            "Wall time: 350 ms\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}